## Madelon-Data-Set

### Introduction

The Center for Machine Learning and Intelligent Systems at the University of California, Irvine, offers a [Machine Learning Repository](http://archive.ics.uci.edu/ml/index.php) with hundreds of data sets for the machine learning community. This problem statement utilizes the [**Madelon** data set](http://archive.ics.uci.edu/ml/datasets/madelon).

Here is a brief overview of the dataset:  
1.  Domain:  Artificial
2.  Problem Statement:  Classify Random Data (Training, Validating, Testing)
3.  Description of Data Set: 500 Attributes with 4400 Instances, Random, Multivariate, Highly Non-linear
4.  Proposed Solution:  Kernel Methods and SVMs
5.  Benchmark Model:  Logistic Regression
6.  Performance Metrics:  BER and AUC

### Domain - Artificial

MADELON is an artificial dataset that was part of the NIPS 2003 feature selection challenge. It is a two-class classification problem with continuous input variables. The difficulty in this problem is that it is multivariate and highly non-linear. This data set was generated by the *hypercube_data.m* program.

The idea for this program originated with the study, ["Grafting: Fast, Incremental Feature Selection by Gradient Descent in Function Space," Simon Perkins, Kevin Lacker, James Theiler](http://www.jmlr.org/papers/volume3/perkins03a/perkins03a.pdf). It was first introduced in the NIPS 2003 artifical selection challenge. A summary of the results can be found [here](http://clopinet.com/isabelle/Projects/NIPS2003/ggad-nips04.pdf)

### Problem Statement

MADELON is an artificial dataset containing data points grouped in 32 clusters placed on the vertices of a five dimensional hypercube and randomly labeled +1 or -1. The five dimensions constitute 5 informative features. 15 linear combinations of those features were added to form a set of 20 (redundant) informative features. Based on those 20 features, the goal is to identify and select the random relevant features and use them to predict the random labels for the data set, the integers *+1* and *-1*. Additional distractor features called 'probes' with no predictive power were added. The order of the features and patterns were randomized. 

Inputs: Randomly-generated integers arrayed in 500 columns  
Outputs: Prediction labels, *+1* and *-1*

The purpose of this dataset is to explore the cabilities of machine learning under such ambiguous circumstances. Ideally, the approach is to tackle the problem by training different ML algorithms to fit the MADELON training data. The model's parameters would be adjusted to find the best fit to the training data. Once an acceptable fit was found, the "fitted" model would be run against the MADELON validation data for evaluation. If these results are satisfactory, the model would be run against the MADELON test data set for a final fit and evaluation. By using different types of classification models (logistic regression, decision trees, random forests, naive Bayes, neural networks, kernels, etc.), it might be possible to find an approach that improves performance

### Description of the Data Set

The dataset contains 3 sets: training, validation, and test set. It consists of 500 features, of which 480 are probes and 20 are real. Based on those features, one must separate it into *+1* or *-1*. There are 2200 positive examples and 2200 negative examples. All values are integers.

Here is a distribution of the examples:  

| Set | Positive Examples | Negative Examples | Total |  
|-----|----|-----|----|  
| Training Set | 1000 (45%) | 1000 (45%) | 2000 |   
| Validation Set | 300 (14%) | 300 (14%) | 600 |  
| Test Set | 900 (41%) | 900 (41%) | 1800 |   
| Total | 2200 | 2200 | 4400 |  

Data on the data sets, their dimensions, and memory usage follow:  

| Set            | Dimensions | Memory (in MB) |
|----------------|------------|----------------|
| Training Set   | 200 x 500  | 6.9            |
| Validation Set | 600 x 500  | 1.2            |
| Test Set       | 1800 x 500 | 3.5            |
| Labels         | 2000 x 1   | .0085          |

The data set is considered dense, that is all rows are populated and no values are missing. It is a multivariate data set with a bimodal distribution.

### Proposed Solution

According to the organizers of the 2003 NIPS challenge, **kernel methods** were the most popular for approaching the classification problem, and most kernel methods were **SVMs**.  For MADELON specifically, "all best ranking groups used a Gaussian kernel."
Training and testing a variety of methods and models for both feature selection and classification will most likely provide a satisfactory solution.

### Benchmark Model

A **logistic regression model** will be used as the benchmark because of its simplistic classification. It will provide a base line to  measure more sophisticated models.

### Performance Metrics

The **balanced error rate (BER)** and **area under the ROC curve (AUC)** will be used as appropriate performance metrics.  Since MADELON results in a binary output, the "Results Analysis" considered BER = 1 - AUC. Other considerations are the fraction of features selected and the fraction of probes found in the feature set selected.
